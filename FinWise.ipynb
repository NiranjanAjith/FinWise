{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aioont/KH012-FinWise/blob/main/FinWise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JD0pmsrdNz0"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eqh58nsCde5D"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#for debug\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnCQYPalFJt3"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUMf7-wVckMz"
      },
      "outputs": [],
      "source": [
        "#read file\n",
        "df = pd.read_csv(\"/content/nsestockhistoricalratios.csv\")\n",
        "\n",
        "#Median Imputation\n",
        "def fill_with_median(column):\n",
        "  try:\n",
        "    column_median = column.median(skipna=True)\n",
        "  except (ValueError, TypeError):\n",
        "    column_median = 0.0\n",
        "  return column.fillna(column_median)\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = fill_with_median(df[col])\n",
        "\n",
        "#split dataframe on companies\n",
        "stock = {}\n",
        "for index, row in df.iterrows():\n",
        "    key = row['Stock']\n",
        "    if key not in stock:\n",
        "        stock[key] = pd.DataFrame(columns=df.columns)\n",
        "        continue\n",
        "    stock[key] = pd.concat([stock[key], row.to_frame().T], ignore_index=True)\n",
        "\n",
        "#reshaping dataframe\n",
        "drop = []\n",
        "for key in stock:\n",
        "  stock[key].drop(['Stock'], axis=1, inplace=True)\n",
        "  company = pd.pivot_table(stock[key], index=\"Year\")\n",
        "\n",
        "  #min-max scaling\n",
        "  for col in company.columns:\n",
        "    normalized_values = (company[col] - np.min(company[col])) / (np.max(company[col]) - np.min(company[col]))\n",
        "    company.loc[:, col] = normalized_values\n",
        "\n",
        "  stock[key] = company\n",
        "  num_rows = stock[key].shape[0]\n",
        "\n",
        "  if num_rows:\n",
        "    file_name = f\"dataset/forheatmap_{key}.csv\"\n",
        "    stock[key].to_csv(file_name, index=True)\n",
        "  else:\n",
        "    drop.append(key)\n",
        "\n",
        "for key in drop:\n",
        "  stock.pop(key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##debug##\n",
        "\n",
        "# df = pd.read_csv(\"/content/nsestockhistoricalratios.csv\", na_values=['', ',,', np.NaN, 'NULL'])\n",
        "\n",
        "# stock = {}\n",
        "# for index, row in df.iterrows():\n",
        "#     key = row['Stock']\n",
        "#     if key not in stock:\n",
        "#         stock[key] = pd.DataFrame(columns=df.columns)\n",
        "#         continue\n",
        "#     stock[key] = pd.concat([stock[key], row.to_frame().T], ignore_index=True)\n",
        "\n",
        "i = 1\n",
        "for key in stock:\n",
        "  stock[key].dropna(axis=0)\n",
        "  dataframe_size = stock[key].shape   # Get the size of the DataFrame\n",
        "  num_rows, num_columns = dataframe_size   # Extract the number of rows and columns\n",
        "  num_na = stock[key].isna().sum().sum()\n",
        "  if num_rows and num_columns == 98 and num_na == 0:\n",
        "    print(f\"{i}) {key}: rows={num_rows}; columns={num_columns}; NaN={num_na}\")\n",
        "    i+=1\n",
        "\n",
        "  # input(\"Enter to continue\")\n",
        "  # clear_output(wait=True)\n",
        "\n",
        "!zip -r /content/file.zip /content/dataset\n",
        "files.download(\"/content/file.zip\")\n"
      ],
      "metadata": {
        "id": "yxvm7RaQVYFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTYp1Ok1Hs2O"
      },
      "outputs": [],
      "source": [
        "for key in stock:\n",
        "  file_name = f\"/content/dataset/forheatmap_{key}.csv\"\n",
        "  na = [-99, 99, 'NULL', '']\n",
        "  stock[key] = pd.read_csv(file_name, na_values=na)\n",
        "\n",
        "  print(stock[key].isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htK8ledl9771"
      },
      "outputs": [],
      "source": [
        "#Creating Heatmaps for each company\n",
        "for key in list(stock.keys()):\n",
        "  stock[key].drop(['Stock'], axis=1, inplace=True)\n",
        "  company = pd.pivot_table(stock[key], index=\"Year\")\n",
        "\n",
        "  #min-max scaling\n",
        "  for col in company.columns:\n",
        "    company[col] = (company[col] - np.min(company[col])) / (np.max(company[col]) - np.min(company[col]))\n",
        "\n",
        "  sns.heatmap(company, cmap=\"YlGnBu\", fmt=\"0.0f\")\n",
        "  # filename = f\"heatmap_{key}.png\"\n",
        "  # plt.savefig(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCLSsn02vAN3"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdNGEOOGvDfI"
      },
      "outputs": [],
      "source": [
        "ClassifyStock = Sequential([\n",
        "    Conv2D(64, (58,5), strides=(5,5), activation='relu', input_size=(640,480,3)),\n",
        "    MaxPool2D((5,5)),\n",
        "\n",
        "    Conv2D(64, (58,5), strides=(5,5), activation='relu', input_size=(640,480,3)),\n",
        "    MaxPool2D((5,5)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfLONFrh8g7E"
      },
      "source": [
        "Model Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nxPcuda8gY5"
      },
      "outputs": [],
      "source": [
        "ClassifyStock.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZGKQTfUFFzmkT/bqK09Fg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}