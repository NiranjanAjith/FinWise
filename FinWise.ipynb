{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aioont/KH012-FinWise/blob/main/FinWise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9JD0pmsrdNz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb793e5e-acfb-4c6a-c5de-260ae9c08d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eqh58nsCde5D"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#for debug\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnCQYPalFJt3"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUMf7-wVckMz"
      },
      "outputs": [],
      "source": [
        "#read file\n",
        "df = pd.read_csv(\"/content/nsestockhistoricalratios.csv\")\n",
        "\n",
        "#Median Imputation\n",
        "def fill_with_median(column):\n",
        "  try:\n",
        "    column_median = column.median(skipna=True)\n",
        "  except (ValueError, TypeError):\n",
        "    column_median = 0.5\n",
        "  return column.fillna(column_median)\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = fill_with_median(df[col])\n",
        "\n",
        "#Mean Imputation\n",
        "def fill_with_mean(column):\n",
        "  try:\n",
        "    mean = column.mean(skipna=True)\n",
        "  except (RuntimeWarning):\n",
        "    mean = 0.5\n",
        "  return column.fillna(mean)\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = fill_with_mean(df[col])\n",
        "\n",
        "#Deleteing rows with missing values\n",
        "df.dropna(axis=0, inplace=True)\n",
        "\n",
        "#split dataframe on companies\n",
        "stock = {}\n",
        "for index, row in df.iterrows():\n",
        "    key = row['Stock']\n",
        "    if key not in stock:\n",
        "        stock[key] = pd.DataFrame(columns=df.columns)\n",
        "        continue\n",
        "    stock[key] = pd.concat([stock[key], row.to_frame().T], ignore_index=True)\n",
        "\n",
        "#reshaping dataframe\n",
        "drop = []\n",
        "for key in stock:\n",
        "  stock[key].drop(['Stock'], axis=1, inplace=True)\n",
        "  company = pd.pivot_table(stock[key], index=\"Year\")\n",
        "\n",
        "  #min-max scaling\n",
        "  for col in company.columns:\n",
        "    try:\n",
        "      normalized_values = (company[col] - np.min(company[col])) / (np.max(company[col]) - np.min(company[col]))\n",
        "    except (ZeroDivisionError):\n",
        "      normalized_values += pd.Series([0.5])\n",
        "    company.loc[:, col] = normalized_values\n",
        "\n",
        "  #data cleaning\n",
        "  company.dropna(axis=0, inplace=True)\n",
        "  #Mean Imputing\n",
        "  for col in company.columns:\n",
        "    company[col] = fill_with_mean(company[col])\n",
        "  #Median Imputing\n",
        "  for col in company.columns:\n",
        "    company[col] = fill_with_median(company[col])\n",
        "\n",
        "  stock[key] = company\n",
        "  num_rows = stock[key].shape[0]\n",
        "  if num_rows:\n",
        "    pass\n",
        "  else:\n",
        "    drop.append(key)\n",
        "\n",
        "for key in drop:\n",
        "  stock.pop(key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in stock:\n",
        "  try:\n",
        "    sns.heatmap(stock[key], cmap=\"gray\")\n",
        "    filename = f\"heatmaps/heatmap_{key}.png\"\n",
        "    plt.savefig(filename)\n",
        "  except (ValueError):\n",
        "    pass"
      ],
      "metadata": {
        "id": "vKLnt9ED8n3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/heatmaps\n",
        "files.download(\"/content/file.zip\")"
      ],
      "metadata": {
        "id": "3Cncq1i3wz9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCLSsn02vAN3"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdNGEOOGvDfI"
      },
      "outputs": [],
      "source": [
        "ClassifyStock = Sequential([\n",
        "    Conv2D(64, (58,5), strides=(5,5), activation='relu', input_size=(640,480,3)),\n",
        "    MaxPool2D((5,5)),\n",
        "\n",
        "    Conv2D(64, (58,5), strides=(5,5), activation='relu', input_size=(640,480,3)),\n",
        "    MaxPool2D((5,5)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfLONFrh8g7E"
      },
      "source": [
        "Model Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nxPcuda8gY5"
      },
      "outputs": [],
      "source": [
        "ClassifyStock.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwAA6r4TCFBGdCiNj40and",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}